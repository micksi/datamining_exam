{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import Orange\n",
    "\n",
    "def get_user_profile(user_id, df_rating, df_a_fatures):\n",
    "    \n",
    "    # To be used only if the user profiles file is not already created\n",
    "    df_user = df_rating.loc[df_rating['user_id'] == user_id]\n",
    "    df_merged = pd.merge(df_user, df_a_fatures, how='left', left_on='anime_id', right_on='anime_id').drop(['anime_id', 'rating'], axis=1)\n",
    "    \n",
    "    avg_genre = df_merged[df_merged.columns.difference(['user_id', 'anime_id', 'rating'])].sum(axis=1)\n",
    "    \n",
    "    # Count only 1's\n",
    "    df_user_sum = df_merged.sum(axis=0)\n",
    "    df_user_sum.user_id = user_id\n",
    "    df_user_sum['rating'] = 10.0\n",
    "    df_user_sum['genre_count'] = avg_genre.sum() / float(len(avg_genre))\n",
    "    \n",
    "    return df_user_sum\n",
    "#\n",
    "def get_user_profiles(df_animes_vector, df_rating, n_users=50):\n",
    "    \n",
    "    # To be used only if the user profiles file is not already created\n",
    "    \n",
    "    # first n_users\n",
    "    users = list(df_rating['user_id'].unique())[:n_users] \n",
    "\n",
    "    # Create user profiles:\n",
    "    df_user_profiles = pd.DataFrame()\n",
    "    i = 0\n",
    "    for u in users:\n",
    "        u_prof = get_user_profile(u, df_rating, df_animes_vector)\n",
    "        df_user_profiles = df_user_profiles.append(u_prof, ignore_index = True)\n",
    "        i = i+1\n",
    "        if i%100 ==0:\n",
    "            print(\"Completed users:\",i)\n",
    "\n",
    "    return df_user_profiles\n",
    "#\n",
    "def normalize(df_user_profiles):\n",
    "    x = df_user_profiles.iloc[:,0:-2].values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    x_scaled = min_max_scaler.fit_transform(x.T)\n",
    "    \n",
    "    df_scaled = pd.DataFrame(x_scaled.T, columns=df_user_profiles.columns.difference(['user_id','rating','genre']))\n",
    "    \n",
    "    df_scaled['user_id'] = df_user_profiles['user_id'].values\n",
    "    df_scaled['genre_count'] = map(lambda x: x /10.0, df_user_profiles['genre_count'].values)\n",
    "    df_scaled['rating'] = 1.0\n",
    "    \n",
    "    return df_scaled\n",
    "#\n",
    "def get_userids_by_indices(indices, df_user_prof_norm):\n",
    "    users = []\n",
    "    for i in indices:\n",
    "       uid = df_user_prof_norm.loc[i]['user_id']\n",
    "       users.append(uid)\n",
    "    return users    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations_per_user(user_id, k, df_user_prof_norm, df_rating):\n",
    "\n",
    "    # find closest k user profiles\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(df_user_prof_norm.drop(['user_id','rating','genre_count'], axis=1))\n",
    "    user_prof = df_user_prof_norm[df_user_prof_norm['user_id'] == user_id]\n",
    "    user_prof = user_prof.drop(['user_id','rating','genre_count'], axis=1)\n",
    "\n",
    "    # Get closest neighbours\n",
    "    distances, indices = nbrs.kneighbors(user_prof)\n",
    "    print(\"Closest neighbours identified!\")\n",
    "    \n",
    "    # get user_ids\n",
    "    uids = get_userids_by_indices(indices[0], df_user_prof_norm)\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    u_animes = []\n",
    "    for uid in uids:\n",
    "        u_animes.append(df_rating[df_rating['user_id'] == uid]['anime_id'].tolist())\n",
    "    with open('anime_trans.basket', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(u_animes)\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # !!!!! Get the transactions directly from the list, not from the .basket file !!!!!\n",
    "\n",
    "    # Get all training transactions\n",
    "\n",
    "    data = Orange.data.Table(\"anime_trans.basket\") #Orange.data.Table(\"anime_trans.basket\")\n",
    "\n",
    "    # This is the user we would like to recommend something for\n",
    "    target_user = data[0]\n",
    "    target_user_animes = data[0].get_metas(str).keys()\n",
    "\n",
    "    # Drop the user's data from the transactions list\n",
    "    data = data.get_items(range(1,len(data)))\n",
    "\n",
    "    # Generate recommendation rules\n",
    "    support_threshold = 0.5\n",
    "    confidence_threshold = 0.8\n",
    "    rulesOK = False\n",
    "    while rulesOK is False:\n",
    "        try:\n",
    "            rules = Orange.associate.AssociationRulesSparseInducer(data, support = support_threshold, confidence = confidence_threshold,\n",
    "                                                                   max_item_sets = 100000)\n",
    "            rulesOK = True\n",
    "        except:\n",
    "            print(support_threshold, confidence_threshold)\n",
    "            if confidence_threshold == 1:\n",
    "                support_threshold += 0.1\n",
    "            else:\n",
    "                confidence_threshold += 0.1\n",
    "            \n",
    "\n",
    "    # print \"%4s\\t %4s  %s %s\" % (\"AnimeId\", \"Lift\", \"Support\", \"Conf\")\n",
    "\n",
    "    recommendations = {}\n",
    "    for r in rules:\n",
    "\n",
    "        # Compare the generated rules with a specific instance from the transactions list\n",
    "        if(r.n_right==1):\n",
    "            recommendation = str(r.right.get_metas(str).keys()[0])\n",
    "            if recommendation not in target_user_animes:\n",
    "                #if r.applies_left(target_user):\n",
    "                try:\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                except:\n",
    "                    recommendations[r.n_left] = []\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                    # print \"%4.2f %4.4f %s %s\" % (r.support, r.confidence, r, r.lift)\n",
    "\n",
    "    user_recommendations = []\n",
    "    for i, r in recommendations.iteritems():\n",
    "        recommendations[i].sort(key=lambda x: (x.lift, x.support, x.confidence), reverse=True)\n",
    "\n",
    "    for recommendation_length in sorted(recommendations.keys(), reverse=True):\n",
    "        if len(user_recommendations) == 10:\n",
    "            break\n",
    "        for recommendation in recommendations[recommendation_length]:\n",
    "            anime_id = str(recommendation.right.get_metas(str).keys()[0])\n",
    "    #         print recommendation\n",
    "    #         print anime_id, \"\\t\", recommendation.lift, recommendation.support, recommendation.confidence\n",
    "            if anime_id not in user_recommendations:\n",
    "                user_recommendations.append(anime_id)\n",
    "            if len(user_recommendations) == 10:\n",
    "                break\n",
    "    return user_recommendations\n",
    "    # Orange.associate.AssociationRulesSparseInducer.get_itemsets(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the user profiles from the user_profiles_final.csv file\n",
    "\n",
    "user_profiles = \"raw/user_profiles_final.csv\"\n",
    "df_user_profiles = pd.read_csv(user_profiles)\n",
    "\n",
    "file_rating = \"raw/rating_train.csv\"\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "\n",
    "users_ids = list(df_user_profiles['user_id'].unique())\n",
    "df_user_prof_norm = normalize(df_user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clust(df_user_prof_norm):\n",
    "    from sklearn.cluster import KMeans\n",
    "    user_prof = df_user_prof_norm.drop(['user_id','rating','genre_count'], axis=1)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=100 , algorithm='auto', n_init=1, n_jobs=-1)\n",
    "    kmeans.fit(user_prof)\n",
    "    print(kmeans.cluster_centers_)\n",
    "    return(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.09128263e-01   4.57965925e-01   1.07265688e-02 ...,   3.22109893e-02\n",
      "    9.99599169e-04   8.41595709e-04]\n",
      " [  5.78211079e-01   5.10521080e-01   2.88038679e-03 ...,   2.56229343e-02\n",
      "    4.04975032e-03   5.53003865e-04]\n",
      " [  9.19007630e-01   4.24750777e-01   1.65608468e-02 ...,   4.25312528e-02\n",
      "    6.52309804e-03   3.94227103e-04]\n",
      " ..., \n",
      " [  9.97384935e-01   4.08449522e-01   8.66169658e-03 ...,   6.82887755e-02\n",
      "    3.30599247e-03   9.25300723e-04]\n",
      " [  9.99822758e-01   3.79100585e-01   5.53230179e-03 ...,   6.07131735e-02\n",
      "    1.01148592e-03   2.46692039e-04]\n",
      " [  9.16414808e-01   3.49484270e-01   1.44481115e-03 ...,   7.33968629e-02\n",
      "    4.32256152e-04   1.00597956e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([23, 11, 11, ..., 83, 34, 15])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust(df_user_prof_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = Out[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60785L,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_user_prof_norm[\"ClustLabel\"] = pd.Series(test, index=df_user_prof_norm.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Action', u'Adventure', u'Cars', u'Comedy', u'Dementia', u'Demons',\n",
       "       u'Drama', u'Ecchi', u'Fantasy', u'Game', u'Harem', u'Hentai',\n",
       "       u'Historical', u'Horror', u'Josei', u'Kids', u'Magic', u'Martial Arts',\n",
       "       u'Mecha', u'Military', u'Music', u'Mystery', u'Parody', u'Police',\n",
       "       u'Psychological', u'Romance', u'Samurai', u'School', u'Sci-Fi',\n",
       "       u'Seinen', u'Shoujo', u'Shoujo Ai', u'Shounen', u'Shounen Ai',\n",
       "       u'Slice of Life', u'Space', u'Sports', u'Super Power', u'Supernatural',\n",
       "       u'Thriller', u'Vampire', u'Yaoi', u'Yuri', u'genre_count', u'user_id',\n",
       "       u'rating', u'ClustLabel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_prof_norm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for user    1\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "(0.6, 1.0)\n",
      "Results for user    3\t \n",
      "Closest neighbours identified!\n",
      "Results for user    4\t \n",
      "Closest neighbours identified!\n",
      "Results for user    5\t \n",
      "Closest neighbours identified!\n",
      "Results for user    6\t \n",
      "Closest neighbours identified!\n",
      "Results for user    7\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user    8\t \n",
      "Closest neighbours identified!\n",
      "Results for user   11\t \n",
      "Closest neighbours identified!\n",
      "Results for user   12\t \n",
      "Closest neighbours identified!\n",
      "Results for user   13\t \n",
      "Closest neighbours identified!\n",
      "Results for user   14\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user   16\t \n",
      "Closest neighbours identified!\n",
      "Results for user   17\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user   18\t \n",
      "Closest neighbours identified!\n",
      "Results for user   19\t \n",
      "Closest neighbours identified!\n",
      "Results for user   20\t \n",
      "Closest neighbours identified!\n",
      "Results for user   21\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "(0.6, 1.0)\n",
      "Results for user   22\t \n",
      "Closest neighbours identified!\n",
      "Results for user   23\t \n",
      "Closest neighbours identified!\n",
      "Results for user   24\t \n",
      "Closest neighbours identified!\n",
      "Results for user   25\t \n",
      "Closest neighbours identified!\n",
      "Results for user   26\t \n",
      "Closest neighbours identified!\n",
      "Results for user   27\t \n",
      "Closest neighbours identified!\n",
      "Results for user   28\t \n",
      "Closest neighbours identified!\n",
      "Results for user   29\t \n",
      "Closest neighbours identified!\n",
      "Results for user   30\t \n",
      "Closest neighbours identified!\n",
      "Results for user   31\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user   32\t \n",
      "Closest neighbours identified!\n",
      "Results for user   33\t \n",
      "Closest neighbours identified!\n",
      "Results for user   34\t \n",
      "Closest neighbours identified!\n",
      "Results for user   35\t \n",
      "Closest neighbours identified!\n",
      "Results for user   37\t \n",
      "Closest neighbours identified!\n",
      "Results for user   38\t \n",
      "Closest neighbours identified!\n",
      "Results for user   39\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user   40\t \n",
      "Closest neighbours identified!\n",
      "Results for user   41\t \n"
     ]
    }
   ],
   "source": [
    "recommendations = {}\n",
    "\n",
    "with open('collaborative.csv', 'ab') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for i in users_ids[:100]:\n",
    "        print (\"Results for user %4d\\t \" % (i))\n",
    "        rec = get_collaborative_recommendations_per_user(user_id=i, k=11, df_user_prof_norm=df_user_prof_norm, df_rating=df_rating)\n",
    "        recommendations[i] = rec\n",
    "        writer.writerow([i, recommendations[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the user profiles from the raw data\n",
    "\n",
    "file_anime = \"raw/anime.csv\"\n",
    "file_rating = \"raw/rating_train.csv\"\n",
    "\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "df_animes = pd.read_csv(file_anime)\n",
    "df_animes_genres = pd.get_dummies(df_animes['genre'].str.get_dummies(sep=\", \")) # creates genre vectors\n",
    "users_ids = list(df_rating['user_id'].unique())\n",
    "df_animes_vector = pd.concat([df_animes['anime_id'], df_animes_genres], axis=1) # anime_id + genre vector\n",
    "\n",
    "# Get user profiles; then normalize \n",
    "\n",
    "# df_user_profiles = get_user_profiles(df_animes_vector, df_rating, n_users=len(users_ids))\n",
    "# df_user_profiles.to_csv(\"user_profiles_final.csv\", index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_reading = pd.io.parsers.read_csv('collaborative_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_reading[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
