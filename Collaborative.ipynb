{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import Orange\n",
    "\n",
    "def get_user_profile(user_id, df_rating, df_a_fatures):\n",
    "    df_user = df_rating.loc[df_rating['user_id'] == user_id]\n",
    "    df_merged = pd.merge(df_user, df_a_fatures, how='left', left_on='anime_id', right_on='anime_id').drop(['anime_id', 'rating'], axis=1)\n",
    "    \n",
    "    avg_genre = df_merged[df_merged.columns.difference(['user_id', 'anime_id', 'rating'])].sum(axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Count only 1's\n",
    "    df_user_sum = df_merged.sum(axis=0)\n",
    "    df_user_sum.user_id = user_id\n",
    "    df_user_sum['rating'] = 10.0\n",
    "    df_user_sum['genre_count'] = avg_genre.sum() / float(len(avg_genre))\n",
    "    \n",
    "    return df_user_sum\n",
    "#\n",
    "def get_user_profiles(df_animes_vector, df_rating, n_users=50):\n",
    "    # first n_users\n",
    "    users = list(df_rating['user_id'].unique())[:n_users] \n",
    "\n",
    "    # Create user profiles:\n",
    "    df_user_profiles = pd.DataFrame()\n",
    "    for u in users:\n",
    "        u_prof = get_user_profile(u, df_rating, df_animes_vector)\n",
    "        df_user_profiles = df_user_profiles.append(u_prof, ignore_index = True)\n",
    "    return df_user_profiles\n",
    "#\n",
    "def normalize(df_user_profiles):\n",
    "    x = df_user_profiles.iloc[:,1:-1].values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    x_scaled = min_max_scaler.fit_transform(x.T)\n",
    "    \n",
    "    df_scaled = pd.DataFrame(x_scaled.T, columns=df_user_profiles.columns.difference(['user_id','rating','genre']))\n",
    "    \n",
    "    df_scaled['user_id'] = df_user_profiles['user_id'].values\n",
    "    df_scaled['genre_count'] = map(lambda x: x /10.0, df_user_profiles['genre_count'].values)\n",
    "    df_scaled['rating'] = 1.0\n",
    "    \n",
    "    return df_scaled\n",
    "#\n",
    "def get_userids_by_indices(indices, df_user_prof_norm):\n",
    "    users = []\n",
    "    for i in indices:\n",
    "       uid = df_user_prof_norm.loc[i]['user_id']\n",
    "       users.append(uid)\n",
    "    return users    \n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_anime = \"raw/anime.csv\"\n",
    "file_rating = \"raw/rating.csv\"\n",
    "\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "df_animes = pd.read_csv(file_anime)\n",
    "df_animes_genres = pd.get_dummies(df_animes['genre'].str.get_dummies(sep=\", \")) # creates genre vectors\n",
    "df_animes_vector = pd.concat([df_animes['anime_id'], df_animes_genres], axis=1) # anime_id + genre vector\n",
    "\n",
    "# Get user profiles; then normalize \n",
    "df_user_profiles = get_user_profiles(df_animes_vector, df_rating, )\n",
    "df_user_prof_norm = normalize(df_user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find closest k user profiles\n",
    "k = 11\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(df_user_prof_norm.iloc[:,1:])\n",
    "user_id = 3\n",
    "user_prof = df_user_prof_norm[df_user_prof_norm['user_id'] == user_id]\n",
    "user_prof = user_prof.drop('user_id', axis=1)\n",
    "\n",
    "# Get closest neighbours\n",
    "distances, indices = nbrs.kneighbors(user_prof)\n",
    "\n",
    "# get user_ids\n",
    "uids = get_userids_by_indices(indices[0], df_user_prof_norm)\n",
    "print uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_animes = []\n",
    "for uid in uids:\n",
    "    u_animes.append(df_rating[df_rating['user_id'] == uid]['anime_id'].tolist())\n",
    "with open('anime_trans.basket', 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(u_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !!!!! Get the transactions directly from the list, not from the .basket file !!!!!\n",
    "\n",
    "# Get all training transactions\n",
    "\n",
    "data = Orange.data.Table(\"anime_trans.basket\") #Orange.data.Table(\"anime_trans.basket\")\n",
    "\n",
    "# This is the user we would like to recommend something for\n",
    "target_user = data[0]\n",
    "target_user_animes = data[0].get_metas(str).keys()\n",
    "\n",
    "# Drop the user's data from the transactions list\n",
    "data = data.get_items(range(1,len(data)))\n",
    "\n",
    "# Generate recommendation rules\n",
    "\n",
    "rules = Orange.associate.AssociationRulesSparseInducer(data, support = 0.5, confidence = 0.7,\n",
    "                                                       max_item_sets = 100000)\n",
    "\n",
    "# print \"%4s\\t %4s  %s %s\" % (\"AnimeId\", \"Lift\", \"Support\", \"Conf\")\n",
    "\n",
    "recommendations = {}\n",
    "for r in rules:\n",
    "    \n",
    "    # Compare the generated rules with a specific instance from the transactions list\n",
    "    if(r.n_right==1):\n",
    "        recommendation = str(r.right.get_metas(str).keys()[0])\n",
    "        if recommendation not in target_user_animes:\n",
    "            if r.applies_left(target_user):\n",
    "                try:\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                except:\n",
    "                    recommendations[r.n_left] = []\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                # print \"%4.2f %4.4f %s %s\" % (r.support, r.confidence, r, r.lift)\n",
    "\n",
    "user_recommendations = []\n",
    "for i, r in recommendations.iteritems():\n",
    "    recommendations[i].sort(key=lambda x: (x.lift, x.support, x.confidence), reverse=True)\n",
    "    \n",
    "for recommendation_length in sorted(recommendations.keys(), reverse=True):\n",
    "    if len(user_recommendations) == 10:\n",
    "        break\n",
    "    for recommendation in recommendations[recommendation_length]:\n",
    "        anime_id = str(recommendation.right.get_metas(str).keys()[0])\n",
    "#         print recommendation\n",
    "#         print anime_id, \"\\t\", recommendation.lift, recommendation.support, recommendation.confidence\n",
    "        if anime_id not in user_recommendations:\n",
    "            user_recommendations.append(anime_id)\n",
    "        if len(user_recommendations) == 10:\n",
    "            break\n",
    "print user_recommendations\n",
    "# Orange.associate.AssociationRulesSparseInducer.get_itemsets(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations_per_user(user_id, k, df_user_prof_norm):\n",
    "\n",
    "    # find closest k user profiles\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(df_user_prof_norm.drop(['user_id','rating','genre_count'], axis=1))\n",
    "    user_prof = df_user_prof_norm[df_user_prof_norm['user_id'] == user_id]\n",
    "    user_prof = user_prof.drop(['user_id','rating','genre_count'], axis=1)\n",
    "\n",
    "    # Get closest neighbours\n",
    "    distances, indices = nbrs.kneighbors(user_prof)\n",
    "\n",
    "    # get user_ids\n",
    "    uids = get_userids_by_indices(indices[0], df_user_prof_norm)\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    u_animes = []\n",
    "    for uid in uids:\n",
    "        u_animes.append(df_rating[df_rating['user_id'] == uid]['anime_id'].tolist())\n",
    "    with open('anime_trans.basket', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(u_animes)\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # !!!!! Get the transactions directly from the list, not from the .basket file !!!!!\n",
    "\n",
    "    # Get all training transactions\n",
    "\n",
    "    data = Orange.data.Table(\"anime_trans.basket\") #Orange.data.Table(\"anime_trans.basket\")\n",
    "\n",
    "    # This is the user we would like to recommend something for\n",
    "    target_user = data[0]\n",
    "    target_user_animes = data[0].get_metas(str).keys()\n",
    "\n",
    "    # Drop the user's data from the transactions list\n",
    "    data = data.get_items(range(1,len(data)))\n",
    "\n",
    "    # Generate recommendation rules\n",
    "\n",
    "    rules = Orange.associate.AssociationRulesSparseInducer(data, support = 0.5, confidence = 0.7,\n",
    "                                                           max_item_sets = 100000)\n",
    "\n",
    "    # print \"%4s\\t %4s  %s %s\" % (\"AnimeId\", \"Lift\", \"Support\", \"Conf\")\n",
    "\n",
    "    recommendations = {}\n",
    "    for r in rules:\n",
    "\n",
    "        # Compare the generated rules with a specific instance from the transactions list\n",
    "        if(r.n_right==1):\n",
    "            recommendation = str(r.right.get_metas(str).keys()[0])\n",
    "            if recommendation not in target_user_animes:\n",
    "                if r.applies_left(target_user):\n",
    "                    try:\n",
    "                        recommendations[r.n_left].append(r)\n",
    "                    except:\n",
    "                        recommendations[r.n_left] = []\n",
    "                        recommendations[r.n_left].append(r)\n",
    "                    # print \"%4.2f %4.4f %s %s\" % (r.support, r.confidence, r, r.lift)\n",
    "\n",
    "    user_recommendations = []\n",
    "    for i, r in recommendations.iteritems():\n",
    "        recommendations[i].sort(key=lambda x: (x.lift, x.support, x.confidence), reverse=True)\n",
    "\n",
    "    for recommendation_length in sorted(recommendations.keys(), reverse=True):\n",
    "        if len(user_recommendations) == 10:\n",
    "            break\n",
    "        for recommendation in recommendations[recommendation_length]:\n",
    "            anime_id = str(recommendation.right.get_metas(str).keys()[0])\n",
    "    #         print recommendation\n",
    "    #         print anime_id, \"\\t\", recommendation.lift, recommendation.support, recommendation.confidence\n",
    "            if anime_id not in user_recommendations:\n",
    "                user_recommendations.append(anime_id)\n",
    "            if len(user_recommendations) == 10:\n",
    "                break\n",
    "    print user_recommendations\n",
    "    # Orange.associate.AssociationRulesSparseInducer.get_itemsets(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_anime = \"raw/anime.csv\"\n",
    "file_rating = \"omer/rating_train.csv\"\n",
    "\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "df_animes = pd.read_csv(file_anime)\n",
    "df_animes_genres = pd.get_dummies(df_animes['genre'].str.get_dummies(sep=\", \")) # creates genre vectors\n",
    "users_ids = list(df_rating['user_id'].unique())\n",
    "df_animes_vector = pd.concat([df_animes['anime_id'], df_animes_genres], axis=1) # anime_id + genre vector\n",
    "\n",
    "# Get user profiles; then normalize \n",
    "df_user_profiles = get_user_profiles(df_animes_vector, df_rating, n_users=100)\n",
    "df_user_prof_norm = normalize(df_user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "Name: user_id, dtype: float64\n",
      "1    2.0\n",
      "Name: user_id, dtype: float64\n",
      "2    3.0\n",
      "Name: user_id, dtype: float64\n",
      "3    4.0\n",
      "Name: user_id, dtype: float64\n",
      "4    5.0\n",
      "Name: user_id, dtype: float64\n",
      "5    6.0\n",
      "Name: user_id, dtype: float64\n",
      "6    7.0\n",
      "Name: user_id, dtype: float64\n",
      "7    8.0\n",
      "Name: user_id, dtype: float64\n",
      "8    9.0\n",
      "Name: user_id, dtype: float64\n",
      "9    10.0\n",
      "Name: user_id, dtype: float64\n",
      "10    11.0\n",
      "Name: user_id, dtype: float64\n",
      "11    12.0\n",
      "Name: user_id, dtype: float64\n",
      "12    13.0\n",
      "Name: user_id, dtype: float64\n",
      "13    14.0\n",
      "Name: user_id, dtype: float64\n",
      "14    15.0\n",
      "Name: user_id, dtype: float64\n",
      "15    16.0\n",
      "Name: user_id, dtype: float64\n",
      "16    17.0\n",
      "Name: user_id, dtype: float64\n",
      "17    18.0\n",
      "Name: user_id, dtype: float64\n",
      "18    19.0\n",
      "Name: user_id, dtype: float64\n",
      "19    20.0\n",
      "Name: user_id, dtype: float64\n",
      "20    21.0\n",
      "Name: user_id, dtype: float64\n",
      "21    22.0\n",
      "Name: user_id, dtype: float64\n",
      "22    23.0\n",
      "Name: user_id, dtype: float64\n",
      "23    24.0\n",
      "Name: user_id, dtype: float64\n",
      "24    25.0\n",
      "Name: user_id, dtype: float64\n",
      "25    26.0\n",
      "Name: user_id, dtype: float64\n",
      "26    27.0\n",
      "Name: user_id, dtype: float64\n",
      "27    28.0\n",
      "Name: user_id, dtype: float64\n",
      "28    29.0\n",
      "Name: user_id, dtype: float64\n",
      "29    30.0\n",
      "Name: user_id, dtype: float64\n",
      "30    31.0\n",
      "Name: user_id, dtype: float64\n",
      "31    32.0\n",
      "Name: user_id, dtype: float64\n",
      "32    33.0\n",
      "Name: user_id, dtype: float64\n",
      "33    34.0\n",
      "Name: user_id, dtype: float64\n",
      "34    35.0\n",
      "Name: user_id, dtype: float64\n",
      "35    36.0\n",
      "Name: user_id, dtype: float64\n",
      "36    37.0\n",
      "Name: user_id, dtype: float64\n",
      "37    38.0\n",
      "Name: user_id, dtype: float64\n",
      "38    39.0\n",
      "Name: user_id, dtype: float64\n",
      "39    40.0\n",
      "Name: user_id, dtype: float64\n",
      "40    41.0\n",
      "Name: user_id, dtype: float64\n",
      "41    42.0\n",
      "Name: user_id, dtype: float64\n",
      "42    43.0\n",
      "Name: user_id, dtype: float64\n",
      "43    44.0\n",
      "Name: user_id, dtype: float64\n",
      "44    45.0\n",
      "Name: user_id, dtype: float64\n",
      "45    46.0\n",
      "Name: user_id, dtype: float64\n",
      "46    47.0\n",
      "Name: user_id, dtype: float64\n",
      "47    48.0\n",
      "Name: user_id, dtype: float64\n",
      "48    49.0\n",
      "Name: user_id, dtype: float64\n",
      "49    50.0\n",
      "Name: user_id, dtype: float64\n",
      "50    51.0\n",
      "Name: user_id, dtype: float64\n",
      "51    52.0\n",
      "Name: user_id, dtype: float64\n",
      "52    53.0\n",
      "Name: user_id, dtype: float64\n",
      "53    54.0\n",
      "Name: user_id, dtype: float64\n",
      "54    55.0\n",
      "Name: user_id, dtype: float64\n",
      "55    56.0\n",
      "Name: user_id, dtype: float64\n",
      "56    57.0\n",
      "Name: user_id, dtype: float64\n",
      "57    58.0\n",
      "Name: user_id, dtype: float64\n",
      "58    59.0\n",
      "Name: user_id, dtype: float64\n",
      "59    60.0\n",
      "Name: user_id, dtype: float64\n",
      "60    61.0\n",
      "Name: user_id, dtype: float64\n",
      "61    62.0\n",
      "Name: user_id, dtype: float64\n",
      "62    63.0\n",
      "Name: user_id, dtype: float64\n",
      "63    64.0\n",
      "Name: user_id, dtype: float64\n",
      "64    65.0\n",
      "Name: user_id, dtype: float64\n",
      "65    66.0\n",
      "Name: user_id, dtype: float64\n",
      "66    67.0\n",
      "Name: user_id, dtype: float64\n",
      "67    68.0\n",
      "Name: user_id, dtype: float64\n",
      "68    69.0\n",
      "Name: user_id, dtype: float64\n",
      "69    70.0\n",
      "Name: user_id, dtype: float64\n",
      "70    71.0\n",
      "Name: user_id, dtype: float64\n",
      "71    72.0\n",
      "Name: user_id, dtype: float64\n",
      "72    73.0\n",
      "Name: user_id, dtype: float64\n",
      "73    74.0\n",
      "Name: user_id, dtype: float64\n",
      "74    75.0\n",
      "Name: user_id, dtype: float64\n",
      "75    76.0\n",
      "Name: user_id, dtype: float64\n",
      "76    77.0\n",
      "Name: user_id, dtype: float64\n",
      "77    78.0\n",
      "Name: user_id, dtype: float64\n",
      "78    79.0\n",
      "Name: user_id, dtype: float64\n",
      "79    80.0\n",
      "Name: user_id, dtype: float64\n",
      "80    81.0\n",
      "Name: user_id, dtype: float64\n",
      "81    82.0\n",
      "Name: user_id, dtype: float64\n",
      "82    83.0\n",
      "Name: user_id, dtype: float64\n",
      "83    84.0\n",
      "Name: user_id, dtype: float64\n",
      "84    85.0\n",
      "Name: user_id, dtype: float64\n",
      "85    86.0\n",
      "Name: user_id, dtype: float64\n",
      "86    87.0\n",
      "Name: user_id, dtype: float64\n",
      "87    88.0\n",
      "Name: user_id, dtype: float64\n",
      "88    89.0\n",
      "Name: user_id, dtype: float64\n",
      "89    90.0\n",
      "Name: user_id, dtype: float64\n",
      "90    91.0\n",
      "Name: user_id, dtype: float64\n",
      "91    92.0\n",
      "Name: user_id, dtype: float64\n",
      "92    93.0\n",
      "Name: user_id, dtype: float64\n",
      "93    94.0\n",
      "Name: user_id, dtype: float64\n",
      "94    95.0\n",
      "Name: user_id, dtype: float64\n",
      "95    96.0\n",
      "Name: user_id, dtype: float64\n",
      "96    97.0\n",
      "Name: user_id, dtype: float64\n",
      "97    98.0\n",
      "Name: user_id, dtype: float64\n",
      "98    99.0\n",
      "Name: user_id, dtype: float64\n",
      "99    100.0\n",
      "Name: user_id, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100):\n",
    "    print df_user_profiles.iloc[i].to_frame().T.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for user    1\t \n",
      "['18153', '20507', '14741', '1535', '11633', '15225', '15809', '6347', '13659', '8769']\n",
      "Results for user    2\t \n",
      "[]\n",
      "Results for user    3\t \n",
      "['269', '223', '9253', '121']\n",
      "Results for user    4\t \n",
      "['6746', '16894', '9989', '18277', '9253', '22199', '225', '20507', '269', '223']\n",
      "Results for user    5\t \n",
      "['10620', '4181', '2167', '10793', '16498', '1575', '2904', '21881']\n",
      "Results for user    6\t \n",
      "['1575', '2904', '4224', '15809', '6347', '15583', '4181', '14075', '9919', '10620']\n",
      "Results for user    7\t \n",
      "['8074', '20787', '6547', '13759', '8841', '4224', '10790', '16498', '6347', '14813']\n",
      "Results for user    8\t \n",
      "['13659', '15225', '8769', '15809', '6347', '6547', '10080', '9041', '14967', '10719']\n",
      "Results for user    9\t \n",
      "[]\n",
      "Results for user   10\t \n",
      "[]\n",
      "Results for user   11\t \n",
      "['18115', '20', '22319', '11771', '1535', '14513', '3588']\n",
      "Results for user   12\t \n"
     ]
    }
   ],
   "source": [
    "for i in users_ids:\n",
    "    print (\"Results for user %4d\\t \" % (i))\n",
    "    get_collaborative_recommendations_per_user(user_id=i, k=11, df_user_prof_norm=df_user_prof_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
