{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import Orange\n",
    "\n",
    "def get_user_profile(user_id, df_rating, df_a_fatures):\n",
    "    \n",
    "    # To be used only if the user profiles file is not already created\n",
    "    df_user = df_rating.loc[df_rating['user_id'] == user_id]\n",
    "    df_merged = pd.merge(df_user, df_a_fatures, how='left', left_on='anime_id', right_on='anime_id').drop(['anime_id', 'rating'], axis=1)\n",
    "    \n",
    "    avg_genre = df_merged[df_merged.columns.difference(['user_id', 'anime_id', 'rating'])].sum(axis=1)\n",
    "    \n",
    "    # Count only 1's\n",
    "    df_user_sum = df_merged.sum(axis=0)\n",
    "    df_user_sum.user_id = user_id\n",
    "    df_user_sum['rating'] = 10.0\n",
    "    df_user_sum['genre_count'] = avg_genre.sum() / float(len(avg_genre))\n",
    "    \n",
    "    return df_user_sum\n",
    "#\n",
    "def get_user_profiles(df_animes_vector, df_rating, n_users=50):\n",
    "    \n",
    "    # To be used only if the user profiles file is not already created\n",
    "    \n",
    "    # first n_users\n",
    "    users = list(df_rating['user_id'].unique())[:n_users] \n",
    "\n",
    "    # Create user profiles:\n",
    "    df_user_profiles = pd.DataFrame()\n",
    "    i = 0\n",
    "    for u in users:\n",
    "        u_prof = get_user_profile(u, df_rating, df_animes_vector)\n",
    "        df_user_profiles = df_user_profiles.append(u_prof, ignore_index = True)\n",
    "        i = i+1\n",
    "        if i%100 ==0:\n",
    "            print(\"Completed users:\",i)\n",
    "\n",
    "    return df_user_profiles\n",
    "#\n",
    "def normalize(df_user_profiles):\n",
    "    x = df_user_profiles.iloc[:,0:-2].values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    x_scaled = min_max_scaler.fit_transform(x.T)\n",
    "    \n",
    "    df_scaled = pd.DataFrame(x_scaled.T, columns=df_user_profiles.columns.difference(['user_id','rating','genre']))\n",
    "    \n",
    "    df_scaled['user_id'] = df_user_profiles['user_id'].values\n",
    "    df_scaled['genre_count'] = map(lambda x: x /10.0, df_user_profiles['genre_count'].values)\n",
    "    df_scaled['rating'] = 1.0\n",
    "    \n",
    "    return df_scaled\n",
    "#\n",
    "def get_userids_by_indices(indices, df_user_prof_norm):\n",
    "    users = []\n",
    "    for i in indices:\n",
    "       uid = df_user_prof_norm.loc[i]['user_id']\n",
    "       users.append(uid)\n",
    "    return users    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations_per_user(user_id, k, df_user_prof_norm, df_rating):\n",
    "\n",
    "    # find closest k user profiles\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(df_user_prof_norm.drop(['user_id','rating','genre_count'], axis=1))\n",
    "    user_prof = df_user_prof_norm[df_user_prof_norm['user_id'] == user_id]\n",
    "    user_prof = user_prof.drop(['user_id','rating','genre_count'], axis=1)\n",
    "\n",
    "    # Get closest neighbours\n",
    "    distances, indices = nbrs.kneighbors(user_prof)\n",
    "    print(\"Closest neighbours identified!\")\n",
    "    \n",
    "    # get user_ids\n",
    "    uids = get_userids_by_indices(indices[0], df_user_prof_norm)\n",
    "    \n",
    "    # ------------------------------------------------------------\n",
    "    u_animes = []\n",
    "    for uid in uids:\n",
    "        u_animes.append(df_rating[df_rating['user_id'] == uid]['anime_id'].tolist())\n",
    "    with open('anime_trans.basket', 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(u_animes)\n",
    "    # ------------------------------------------------------------\n",
    "    \n",
    "    # !!!!! Get the transactions directly from the list, not from the .basket file !!!!!\n",
    "\n",
    "    # Get all training transactions\n",
    "\n",
    "    data = Orange.data.Table(\"anime_trans.basket\") #Orange.data.Table(\"anime_trans.basket\")\n",
    "\n",
    "    # This is the user we would like to recommend something for\n",
    "    target_user = data[0]\n",
    "    target_user_animes = data[0].get_metas(str).keys()\n",
    "\n",
    "    # Drop the user's data from the transactions list\n",
    "    data = data.get_items(range(1,len(data)))\n",
    "\n",
    "    # Generate recommendation rules\n",
    "    support_threshold = 0.5\n",
    "    confidence_threshold = 0.8\n",
    "    rulesOK = False\n",
    "    while rulesOK is False:\n",
    "        try:\n",
    "            rules = Orange.associate.AssociationRulesSparseInducer(data, support = support_threshold, confidence = confidence_threshold,\n",
    "                                                                   max_item_sets = 100000)\n",
    "            rulesOK = True\n",
    "        except:\n",
    "            print(support_threshold, confidence_threshold)\n",
    "            if confidence_threshold == 1:\n",
    "                support_threshold += 0.1\n",
    "            else:\n",
    "                confidence_threshold += 0.1\n",
    "            \n",
    "\n",
    "    # print \"%4s\\t %4s  %s %s\" % (\"AnimeId\", \"Lift\", \"Support\", \"Conf\")\n",
    "\n",
    "    recommendations = {}\n",
    "    for r in rules:\n",
    "\n",
    "        # Compare the generated rules with a specific instance from the transactions list\n",
    "        if(r.n_right==1):\n",
    "            recommendation = str(r.right.get_metas(str).keys()[0])\n",
    "            if recommendation not in target_user_animes:\n",
    "                #if r.applies_left(target_user):\n",
    "                try:\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                except:\n",
    "                    recommendations[r.n_left] = []\n",
    "                    recommendations[r.n_left].append(r)\n",
    "                    # print \"%4.2f %4.4f %s %s\" % (r.support, r.confidence, r, r.lift)\n",
    "\n",
    "    user_recommendations = []\n",
    "    for i, r in recommendations.iteritems():\n",
    "        recommendations[i].sort(key=lambda x: (x.lift, x.support, x.confidence), reverse=True)\n",
    "\n",
    "    for recommendation_length in sorted(recommendations.keys(), reverse=True):\n",
    "        if len(user_recommendations) == 10:\n",
    "            break\n",
    "        for recommendation in recommendations[recommendation_length]:\n",
    "            anime_id = str(recommendation.right.get_metas(str).keys()[0])\n",
    "    #         print recommendation\n",
    "    #         print anime_id, \"\\t\", recommendation.lift, recommendation.support, recommendation.confidence\n",
    "            if anime_id not in user_recommendations:\n",
    "                user_recommendations.append(anime_id)\n",
    "            if len(user_recommendations) == 10:\n",
    "                break\n",
    "    return user_recommendations\n",
    "    # Orange.associate.AssociationRulesSparseInducer.get_itemsets(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the user profiles from the user_profiles_final.csv file\n",
    "\n",
    "user_profiles = \"raw/user_profiles_final.csv\"\n",
    "df_user_profiles = pd.read_csv(user_profiles)\n",
    "\n",
    "file_rating = \"raw/rating_train.csv\"\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "\n",
    "users_ids = list(df_user_profiles['user_id'].unique())\n",
    "df_user_prof_norm = normalize(df_user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for user    1\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "(0.6, 1.0)\n",
      "Results for user    3\t \n",
      "Closest neighbours identified!\n",
      "Results for user    4\t \n",
      "Closest neighbours identified!\n",
      "Results for user    5\t \n",
      "Closest neighbours identified!\n",
      "Results for user    6\t \n",
      "Closest neighbours identified!\n",
      "Results for user    7\t \n",
      "Closest neighbours identified!\n",
      "(0.5, 0.8)\n",
      "(0.5, 0.9)\n",
      "(0.5, 1.0)\n",
      "Results for user    8\t \n",
      "Closest neighbours identified!\n",
      "Results for user   11\t \n",
      "Closest neighbours identified!\n",
      "Results for user   12\t \n",
      "Closest neighbours identified!\n",
      "Results for user   13\t \n",
      "Closest neighbours identified!\n"
     ]
    }
   ],
   "source": [
    "recommendations = {}\n",
    "\n",
    "with open('collaborative.csv', 'ab') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for i in users_ids[:10]:\n",
    "        print (\"Results for user %4d\\t \" % (i))\n",
    "        rec = get_collaborative_recommendations_per_user(user_id=i, k=11, df_user_prof_norm=df_user_prof_norm, df_rating=df_rating)\n",
    "        recommendations[i] = rec\n",
    "        writer.writerow([i, recommendations[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the user profiles from the raw data\n",
    "\n",
    "file_anime = \"raw/anime.csv\"\n",
    "file_rating = \"raw/rating_train.csv\"\n",
    "\n",
    "df_rating = pd.read_csv(file_rating)\n",
    "df_animes = pd.read_csv(file_anime)\n",
    "df_animes_genres = pd.get_dummies(df_animes['genre'].str.get_dummies(sep=\", \")) # creates genre vectors\n",
    "users_ids = list(df_rating['user_id'].unique())\n",
    "df_animes_vector = pd.concat([df_animes['anime_id'], df_animes_genres], axis=1) # anime_id + genre vector\n",
    "\n",
    "# Get user profiles; then normalize \n",
    "\n",
    "# df_user_profiles = get_user_profiles(df_animes_vector, df_rating, n_users=len(users_ids))\n",
    "# df_user_profiles.to_csv(\"user_profiles_final.csv\", index=False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_reading = pd.io.parsers.read_csv('collaborative_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_reading[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
